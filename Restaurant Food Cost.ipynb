{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a261c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\sumit kaushik\\anaconda3\\lib\\site-packages (3.0.10)\n",
      "Collecting openpyxl\n",
      "  Obtaining dependency information for openpyxl from https://files.pythonhosted.org/packages/30/d0/abcdb0669931be3a98881e6d7851605981693e93a7924061c67d0cd9f292/openpyxl-3.1.4-py2.py3-none-any.whl.metadata\n",
      "  Downloading openpyxl-3.1.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\sumit kaushik\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Downloading openpyxl-3.1.4-py2.py3-none-any.whl (251 kB)\n",
      "   ---------------------------------------- 0.0/251.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/251.4 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/251.4 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 30.7/251.4 kB 217.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/251.4 kB 217.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/251.4 kB 217.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/251.4 kB 217.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/251.4 kB 217.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/251.4 kB 217.9 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 30.7/251.4 kB 217.9 kB/s eta 0:00:02\n",
      "   -------------- ------------------------ 92.2/251.4 kB 187.5 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 122.9/251.4 kB 232.7 kB/s eta 0:00:01\n",
      "   -------------------------------------  245.8/251.4 kB 430.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 251.4/251.4 kB 429.0 kB/s eta 0:00:00\n",
      "Installing collected packages: openpyxl\n",
      "  Attempting uninstall: openpyxl\n",
      "    Found existing installation: openpyxl 3.0.10\n",
      "    Uninstalling openpyxl-3.0.10:\n",
      "      Successfully uninstalled openpyxl-3.0.10\n",
      "Successfully installed openpyxl-3.1.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452b51ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openpyxl\n",
      "Version: 3.1.4\n",
      "Summary: A Python library to read/write Excel 2010 xlsx/xlsm files\n",
      "Home-page: https://openpyxl.readthedocs.io\n",
      "Author: See AUTHORS\n",
      "Author-email: charlie.clark@clark-consulting.eu\n",
      "License: MIT\n",
      "Location: C:\\Users\\Sumit Kaushik\\anaconda3\\Lib\\site-packages\n",
      "Requires: et-xmlfile\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9397b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4089ebca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel('D:\\Data_Train.xlsx')\n",
    "test = pd.read_excel('D:\\Data_Test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c99156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12690, 9), (4231, 8))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760694a8",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "26f826b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate records... didn't remove the duplicate records as it was bringing score down\n",
    "train.duplicated().sum(), test.duplicated().sum()\n",
    "#train.drop_duplicates(keep='first', inplace=True)\n",
    "#train.reset_index(inplace=True)\n",
    "#test.drop_duplicates(keep='first', inplace=True)\n",
    "#test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9288967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>COST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>9438</td>\n",
       "      <td>Malwani, Goan, North Indian</td>\n",
       "      <td>11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Dombivali East</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49 votes</td>\n",
       "      <td>1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING,BAR</td>\n",
       "      <td>13198</td>\n",
       "      <td>Asian, Modern Indian, Japanese</td>\n",
       "      <td>6pm – 11pm (Mon-Sun)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ramapuram</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30 votes</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>10915</td>\n",
       "      <td>North Indian, Chinese, Biryani, Hyderabadi</td>\n",
       "      <td>11am – 3:30pm, 7pm – 11pm (Mon-Sun)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Saligramam</td>\n",
       "      <td>3.8</td>\n",
       "      <td>221 votes</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>6346</td>\n",
       "      <td>Tibetan, Chinese</td>\n",
       "      <td>11:30am – 1am (Mon-Sun)</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Bandra West</td>\n",
       "      <td>4.1</td>\n",
       "      <td>24 votes</td>\n",
       "      <td>800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DESSERT PARLOR</td>\n",
       "      <td>15387</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>11am – 1am (Mon-Sun)</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Lower Parel</td>\n",
       "      <td>3.8</td>\n",
       "      <td>165 votes</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TITLE  RESTAURANT_ID  \\\n",
       "0      CASUAL DINING           9438   \n",
       "1  CASUAL DINING,BAR          13198   \n",
       "2      CASUAL DINING          10915   \n",
       "3        QUICK BITES           6346   \n",
       "4     DESSERT PARLOR          15387   \n",
       "\n",
       "                                     CUISINES  \\\n",
       "0                 Malwani, Goan, North Indian   \n",
       "1              Asian, Modern Indian, Japanese   \n",
       "2  North Indian, Chinese, Biryani, Hyderabadi   \n",
       "3                            Tibetan, Chinese   \n",
       "4                                    Desserts   \n",
       "\n",
       "                                     TIME     CITY        LOCALITY RATING  \\\n",
       "0  11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)    Thane  Dombivali East    3.6   \n",
       "1                    6pm – 11pm (Mon-Sun)  Chennai       Ramapuram    4.2   \n",
       "2     11am – 3:30pm, 7pm – 11pm (Mon-Sun)  Chennai      Saligramam    3.8   \n",
       "3                 11:30am – 1am (Mon-Sun)   Mumbai     Bandra West    4.1   \n",
       "4                    11am – 1am (Mon-Sun)   Mumbai     Lower Parel    3.8   \n",
       "\n",
       "       VOTES  COST  \n",
       "0   49 votes  1200  \n",
       "1   30 votes  1500  \n",
       "2  221 votes   800  \n",
       "3   24 votes   800  \n",
       "4  165 votes   300  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b20e217c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12690 entries, 0 to 12689\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   TITLE          11687 non-null  object\n",
      " 1   RESTAURANT_ID  12690 non-null  int64 \n",
      " 2   CUISINES       12690 non-null  object\n",
      " 3   TIME           12690 non-null  object\n",
      " 4   CITY           12578 non-null  object\n",
      " 5   LOCALITY       12592 non-null  object\n",
      " 6   RATING         12688 non-null  object\n",
      " 7   VOTES          11486 non-null  object\n",
      " 8   COST           12690 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 892.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n",
    "#train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eabcecac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in TITLE 112\n",
      "Unique values in RESTAURANT_ID 11892\n",
      "Unique values in CUISINES 4155\n",
      "Unique values in TIME 2689\n",
      "Unique values in CITY 359\n",
      "Unique values in LOCALITY 1416\n",
      "Unique values in RATING 32\n",
      "Unique values in VOTES 1847\n",
      "Unique values in COST 86\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns:\n",
    "    print(\"Unique values in\", i, train[i].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "943e7cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>RESTAURANT_ID</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>4085</td>\n",
       "      <td>North Indian, Chinese, Mughlai, Kebab</td>\n",
       "      <td>12noon – 12midnight (Mon-Sun)</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Sector 18</td>\n",
       "      <td>4.3</td>\n",
       "      <td>564 votes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>12680</td>\n",
       "      <td>South Indian, Fast Food, Pizza, North Indian</td>\n",
       "      <td>7am – 12:30AM (Mon-Sun)</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Grant Road</td>\n",
       "      <td>4.2</td>\n",
       "      <td>61 votes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>1411</td>\n",
       "      <td>North Indian, Seafood, Biryani, Chinese</td>\n",
       "      <td>11am – 11:30pm (Mon-Sun)</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Marine Lines</td>\n",
       "      <td>3.8</td>\n",
       "      <td>350 votes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "      <td>Biryani</td>\n",
       "      <td>9am – 10pm (Mon, Wed, Thu, Fri, Sat, Sun), 10:...</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>NIT</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1445 votes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUICK BITES</td>\n",
       "      <td>13453</td>\n",
       "      <td>South Indian, Kerala</td>\n",
       "      <td>11am – 10pm (Mon-Sun)</td>\n",
       "      <td>Kochi</td>\n",
       "      <td>Kaloor</td>\n",
       "      <td>3.6</td>\n",
       "      <td>23 votes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           TITLE  RESTAURANT_ID                                      CUISINES  \\\n",
       "0  CASUAL DINING           4085         North Indian, Chinese, Mughlai, Kebab   \n",
       "1    QUICK BITES          12680  South Indian, Fast Food, Pizza, North Indian   \n",
       "2  CASUAL DINING           1411       North Indian, Seafood, Biryani, Chinese   \n",
       "3            NaN            204                                       Biryani   \n",
       "4    QUICK BITES          13453                          South Indian, Kerala   \n",
       "\n",
       "                                                TIME       CITY      LOCALITY  \\\n",
       "0                      12noon – 12midnight (Mon-Sun)      Noida     Sector 18   \n",
       "1                            7am – 12:30AM (Mon-Sun)     Mumbai    Grant Road   \n",
       "2                           11am – 11:30pm (Mon-Sun)     Mumbai  Marine Lines   \n",
       "3  9am – 10pm (Mon, Wed, Thu, Fri, Sat, Sun), 10:...  Faridabad           NIT   \n",
       "4                              11am – 10pm (Mon-Sun)      Kochi        Kaloor   \n",
       "\n",
       "  RATING       VOTES  \n",
       "0    4.3   564 votes  \n",
       "1    4.2    61 votes  \n",
       "2    3.8   350 votes  \n",
       "3    3.8  1445 votes  \n",
       "4    3.6    23 votes  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0528f5",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d7d57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d18ded03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'train' and 'test' are your existing DataFrame objects\n",
    "df = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a1ee1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['TITLE', 'CUISINES', 'TIME', 'CITY', 'LOCALITY', 'RATING', 'VOTES', 'COST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "908d1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_closed(time):\n",
    "    a = re.findall('Closed \\(.*?\\)', time)\n",
    "    if a != []:\n",
    "        return a[0]\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "df['CLOSED'] = df['TIME'].apply(extract_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50a8bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TIME'] = df['TIME'].str.replace(r'Closed \\(.*?\\)','')\n",
    "#df['TIME'] = df['TIME'].str.replace(r'Closed...','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d8da1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RATING'] = df['RATING'].str.replace('NEW', '1')\n",
    "df['RATING'] = df['RATING'].str.replace('-', '1').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ce346361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['VOTES'] = df['VOTES'].str.replace(' votes', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f07b5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CITY'].fillna('Missing', inplace=True)  \n",
    "df['LOCALITY'].fillna('Missing', inplace=True)  \n",
    "df['RATING'].fillna(3.8, inplace=True)  \n",
    "df['VOTES'].fillna(0.0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d8c59a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['COST'] = df['COST'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67034fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>COST</th>\n",
       "      <th>CLOSED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>Malwani, Goan, North Indian</td>\n",
       "      <td>11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Dombivali East</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING,BAR</td>\n",
       "      <td>Asian, Modern Indian, Japanese</td>\n",
       "      <td>6pm – 11pm (Mon-Sun)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ramapuram</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TITLE                        CUISINES  \\\n",
       "0      CASUAL DINING     Malwani, Goan, North Indian   \n",
       "1  CASUAL DINING,BAR  Asian, Modern Indian, Japanese   \n",
       "\n",
       "                                     TIME     CITY        LOCALITY  RATING  \\\n",
       "0  11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)    Thane  Dombivali East     3.6   \n",
       "1                    6pm – 11pm (Mon-Sun)  Chennai       Ramapuram     4.2   \n",
       "\n",
       "   VOTES    COST CLOSED  \n",
       "0   49.0  1200.0     NA  \n",
       "1   30.0  1500.0     NA  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "940218d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 5183)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TITLE'].nunique(), df['CUISINES'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6c8040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mean = df.groupby(['CITY'], axis=0).agg({'RATING': 'mean'}).reset_index()\n",
    "calc_mean.columns = ['CITY','CITY_MEAN_RATING']\n",
    "df = df.merge(calc_mean, on=['CITY'],how='left')\n",
    "\n",
    "calc_mean = df.groupby(['LOCALITY'], axis=0).agg({'RATING': 'mean'}).reset_index()\n",
    "calc_mean.columns = ['LOCALITY','LOCALITY_MEAN_RATING']\n",
    "df = df.merge(calc_mean, on=['LOCALITY'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e7ffd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>COST</th>\n",
       "      <th>CLOSED</th>\n",
       "      <th>CITY_MEAN_RATING</th>\n",
       "      <th>LOCALITY_MEAN_RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>Malwani, Goan, North Indian</td>\n",
       "      <td>11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Dombivali East</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.376271</td>\n",
       "      <td>3.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING,BAR</td>\n",
       "      <td>Asian, Modern Indian, Japanese</td>\n",
       "      <td>6pm – 11pm (Mon-Sun)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ramapuram</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.584588</td>\n",
       "      <td>3.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TITLE                        CUISINES  \\\n",
       "0      CASUAL DINING     Malwani, Goan, North Indian   \n",
       "1  CASUAL DINING,BAR  Asian, Modern Indian, Japanese   \n",
       "\n",
       "                                     TIME     CITY        LOCALITY  RATING  \\\n",
       "0  11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)    Thane  Dombivali East     3.6   \n",
       "1                    6pm – 11pm (Mon-Sun)  Chennai       Ramapuram     4.2   \n",
       "\n",
       "   VOTES    COST CLOSED  CITY_MEAN_RATING  LOCALITY_MEAN_RATING  \n",
       "0   49.0  1200.0     NA          3.376271              3.388889  \n",
       "1   30.0  1500.0     NA          3.584588              3.472222  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3aa4139e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[0;32m      2\u001b[0m tf1 \u001b[38;5;241m=\u001b[39m TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m df_title \u001b[38;5;241m=\u001b[39m tf1\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTITLE\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m df_title \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mdf_title\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mtf1\u001b[38;5;241m.\u001b[39mget_feature_names())\n\u001b[0;32m      6\u001b[0m tf2 \u001b[38;5;241m=\u001b[39m TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), lowercase\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2093\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2087\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2088\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2089\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2090\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2091\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2092\u001b[0m )\n\u001b[1;32m-> 2093\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2095\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1374\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m             )\n\u001b[0;32m   1372\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1377\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1261\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1260\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1262\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1263\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:105\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m decoder(doc)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:238\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    235\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf1 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_title = tf1.fit_transform(df['TITLE'])\n",
    "df_title = pd.DataFrame(data=df_title.toarray(), columns=tf1.get_feature_names())\n",
    "\n",
    "tf2 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_cuisines = tf2.fit_transform(df['CUISINES'])\n",
    "df_cuisines = pd.DataFrame(data=df_cuisines.toarray(), columns=tf2.get_feature_names())\n",
    "\n",
    "tf3 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_city = tf3.fit_transform(df['CITY'])\n",
    "df_city = pd.DataFrame(data=df_city.toarray(), columns=tf3.get_feature_names())\n",
    "\n",
    "tf4 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_locality = tf4.fit_transform(df['LOCALITY'])\n",
    "df_locality = pd.DataFrame(data=df_locality.toarray(), columns=tf4.get_feature_names())\n",
    "\n",
    "tf5 = TfidfVectorizer(ngram_range=(1, 1), lowercase=True)\n",
    "df_time = tf5.fit_transform(df['TIME'])\n",
    "df_time = pd.DataFrame(data=df_time.toarray(), columns=tf5.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d86604e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CUISINES</th>\n",
       "      <th>TIME</th>\n",
       "      <th>CITY</th>\n",
       "      <th>LOCALITY</th>\n",
       "      <th>RATING</th>\n",
       "      <th>VOTES</th>\n",
       "      <th>COST</th>\n",
       "      <th>CLOSED</th>\n",
       "      <th>CITY_MEAN_RATING</th>\n",
       "      <th>LOCALITY_MEAN_RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASUAL DINING</td>\n",
       "      <td>Malwani, Goan, North Indian</td>\n",
       "      <td>11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Dombivali East</td>\n",
       "      <td>3.6</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.376271</td>\n",
       "      <td>3.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASUAL DINING,BAR</td>\n",
       "      <td>Asian, Modern Indian, Japanese</td>\n",
       "      <td>6pm – 11pm (Mon-Sun)</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Ramapuram</td>\n",
       "      <td>4.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.584588</td>\n",
       "      <td>3.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TITLE                        CUISINES  \\\n",
       "0      CASUAL DINING     Malwani, Goan, North Indian   \n",
       "1  CASUAL DINING,BAR  Asian, Modern Indian, Japanese   \n",
       "\n",
       "                                     TIME     CITY        LOCALITY  RATING  \\\n",
       "0  11am – 4pm, 7:30pm – 11:30pm (Mon-Sun)    Thane  Dombivali East     3.6   \n",
       "1                    6pm – 11pm (Mon-Sun)  Chennai       Ramapuram     4.2   \n",
       "\n",
       "   VOTES    COST CLOSED  CITY_MEAN_RATING  LOCALITY_MEAN_RATING  \n",
       "0   49.0  1200.0     NA          3.376271              3.388889  \n",
       "1   30.0  1500.0     NA          3.584588              3.472222  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9d9de37",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'scipy.sparse._csr.csr_matrix'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df_title, df_cuisines, df_city, df_locality, df_time], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTITLE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUISINES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCITY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOCALITY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIME\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    385\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[0;32m    386\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m    387\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[0;32m    388\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[0;32m    389\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[0;32m    390\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[0;32m    391\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:448\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m--> 448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n\u001b[0;32m    449\u001b[0m sample, objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sample_object(objs, ndims, keys, names, levels)\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# Standardize axis parameter to int\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:489\u001b[0m, in \u001b[0;36m_Concatenator._get_ndims\u001b[1;34m(self, objs)\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[0;32m    485\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    486\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot concatenate object of type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly Series and DataFrame objs are valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    488\u001b[0m         )\n\u001b[1;32m--> 489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m    491\u001b[0m     ndims\u001b[38;5;241m.\u001b[39madd(obj\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ndims\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'scipy.sparse._csr.csr_matrix'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df, df_title, df_cuisines, df_city, df_locality, df_time], axis=1) \n",
    "df.drop(['TITLE', 'CUISINES', 'CITY', 'LOCALITY', 'TIME'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5e7f64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['CLOSED'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc6a8fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16921, 33)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "28759f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['COST'].isnull()!=True]\n",
    "test_df = df[df['COST'].isnull()==True]\n",
    "test_df.drop('COST', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d94704fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12690, 33), (4231, 32))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c25838d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['COST'] = np.log1p(train_df['COST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f381a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(labels=['COST'], axis=1)\n",
    "y = train_df['COST'].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a763c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9517, 32), (9517,), (3173, 32), (3173,))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_cv.shape, y_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b469ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt \n",
    "from sklearn.metrics import mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e96209c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train() got an unexpected keyword argument 'verbose_eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 18\u001b[0m\n\u001b[0;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_cv, label\u001b[38;5;241m=\u001b[39my_cv)\n\u001b[0;32m      5\u001b[0m param \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboosting\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgbdt\u001b[39m\u001b[38;5;124m'\u001b[39m,  \n\u001b[0;32m      7\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2_root\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_fraction\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.55\u001b[39m\n\u001b[0;32m     16\u001b[0m          }\n\u001b[1;32m---> 18\u001b[0m lgbm \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mtrain(params\u001b[38;5;241m=\u001b[39mparam,\n\u001b[0;32m     19\u001b[0m                  verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     20\u001b[0m                  train_set\u001b[38;5;241m=\u001b[39mtrain_data,\n\u001b[0;32m     21\u001b[0m                  valid_sets\u001b[38;5;241m=\u001b[39m[test_data])\n\u001b[0;32m     23\u001b[0m y_pred_lgbm \u001b[38;5;241m=\u001b[39m lgbm\u001b[38;5;241m.\u001b[39mpredict(X_cv)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSLE:\u001b[39m\u001b[38;5;124m'\u001b[39m, sqrt(mean_squared_log_error(np\u001b[38;5;241m.\u001b[39mexp(y_cv), np\u001b[38;5;241m.\u001b[39mexp(y_pred_lgbm))))\n",
      "\u001b[1;31mTypeError\u001b[0m: train() got an unexpected keyword argument 'verbose_eval'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "test_data = lgb.Dataset(X_cv, label=y_cv)\n",
    "\n",
    "param = {'objective': 'regression',\n",
    "         'boosting': 'gbdt',  \n",
    "         'metric': 'l2_root',\n",
    "         'learning_rate': 0.05, \n",
    "         'num_iterations': 350,\n",
    "         'num_leaves': 31,\n",
    "         'max_depth': -1,\n",
    "         'min_data_in_leaf': 15,\n",
    "         'bagging_fraction': 0.85,\n",
    "         'bagging_freq': 1,\n",
    "         'feature_fraction': 0.55\n",
    "         }\n",
    "\n",
    "lgbm = lgb.train(params=param,\n",
    "                 verbose_eval=50,\n",
    "                 train_set=train_data,\n",
    "                 valid_sets=[test_data])\n",
    "\n",
    "y_pred_lgbm = lgbm.predict(X_cv)\n",
    "print('RMSLE:', sqrt(mean_squared_log_error(np.exp(y_cv), np.exp(y_pred_lgbm))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0aaf4825",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaggingRegressor.__init__() got an unexpected keyword argument 'base_estimator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaggingRegressor\n\u001b[1;32m----> 2\u001b[0m br \u001b[38;5;241m=\u001b[39m BaggingRegressor(base_estimator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[0;32m      3\u001b[0m                       bootstrap_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, oob_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, warm_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m br\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      5\u001b[0m y_pred_br \u001b[38;5;241m=\u001b[39m br\u001b[38;5;241m.\u001b[39mpredict(X_cv)\n",
      "\u001b[1;31mTypeError\u001b[0m: BaggingRegressor.__init__() got an unexpected keyword argument 'base_estimator'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "br = BaggingRegressor(base_estimator=None, n_estimators=30, max_samples=0.9, max_features=1.0, bootstrap=True, \n",
    "                      bootstrap_features=True, oob_score=True, warm_start=False, n_jobs=1, random_state=42, verbose=1)\n",
    "br.fit(X_train, y_train)\n",
    "y_pred_br = br.predict(X_cv)\n",
    "print('RMSLE:', sqrt(mean_squared_log_error(np.exp(y_cv), np.exp(y_pred_br))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb2683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
